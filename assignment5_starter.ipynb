{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KNN class\n",
    "class KNN:\n",
    "    def __init__(self, k, distance_metric):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X, dtype=float)  # Ensure float type\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def predictTrain(self, X):\n",
    "        X = np.array(X, dtype=float)  # Ensure float type\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = self.compute_distance(self.X_train, x)\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = self.y_train[k_indices]\n",
    "\n",
    "            # Manual mode calculation\n",
    "            unique_labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "            most_common_label = unique_labels[np.argmax(counts)]\n",
    "            predictions.append(most_common_label)\n",
    "\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def predictTest(self, X):\n",
    "        # Predict probabilities for each sample in X\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        return np.array([self._predictTest(x) for x in X])\n",
    "    \n",
    "    def _predictTest(self, x):\n",
    "        distances = self.compute_distance(self.X_train, x)\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        k_nearest_distances = distances[k_indices]\n",
    "        # Weighted voting: weight inversely proportional to distance\n",
    "        weights = 1 / (k_nearest_distances + 1e-5)\n",
    "        weighted_sum = np.sum(weights * k_nearest_labels)\n",
    "        total_weight = np.sum(weights)\n",
    "        prob = weighted_sum / total_weight\n",
    "        return prob\n",
    "\n",
    "    def compute_distance(self, X1, X2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((X1 - X2) ** 2, axis=1))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(X1 - X2), axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "\n",
    "    # Handle missing values by imputation (using median for numerical columns)\n",
    "    for column in train_data.columns:\n",
    "        if train_data[column].isnull().any():\n",
    "            median_value = train_data[column].median()\n",
    "            train_data[column].fillna(median_value, inplace=True)\n",
    "            test_data[column].fillna(median_value, inplace=True)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    X_train = train_data.drop(columns=['id', 'CustomerId', 'Surname', 'Exited'])\n",
    "    y_train = train_data['Exited']\n",
    "    X_test = test_data.drop(columns=['id', 'CustomerId', 'Surname'])\n",
    "\n",
    "    # Map Gender\n",
    "    X_train['Gender'] = X_train['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    X_test['Gender'] = X_test['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "    # One-hot encode Geography\n",
    "    X_train = pd.get_dummies(X_train, columns=['Geography'], drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=['Geography'], drop_first=True)\n",
    "\n",
    "    # Creating interaction features\n",
    "    X_train['Age_Tenure_Ratio'] = X_train['Age'] / (X_train['Tenure'] + 1e-5)  # Avoid division by zero\n",
    "    X_test['Age_Tenure_Ratio'] = X_test['Age'] / (X_test['Tenure'] + 1e-5)\n",
    "    X_train['Balance_Salary_Ratio'] = X_train['Balance'] / (X_train['EstimatedSalary'] + 1e-5)\n",
    "    X_test['Balance_Salary_Ratio'] = X_test['Balance'] / (X_test['EstimatedSalary'] + 1e-5)\n",
    "\n",
    "    # Add new interaction features\n",
    "    X_train['CreditScore_Tenure'] = X_train['CreditScore'] * X_train['Tenure']\n",
    "    X_test['CreditScore_Tenure'] = X_test['CreditScore'] * X_test['Tenure']\n",
    "\n",
    "    X_train['Income_Stability'] = X_train['Balance'] / (X_train['EstimatedSalary'] * (X_train['Tenure'] + 1e-5))\n",
    "    X_test['Income_Stability'] = X_test['Balance'] / (X_test['EstimatedSalary'] * (X_test['Tenure'] + 1e-5))\n",
    "\n",
    "    # Add Credit Score Bucketing\n",
    "    def credit_score_bucket(credit_score):\n",
    "        if credit_score <= 500:\n",
    "            return 'Low'\n",
    "        elif 500 < credit_score <= 700:\n",
    "            return 'Medium'\n",
    "        elif 700 < credit_score <= 850:\n",
    "            return 'High'\n",
    "        else:\n",
    "            return 'Very High'\n",
    "    \n",
    "    # Apply the function to create the new bucketed feature\n",
    "    X_train['CreditScore_Bucket'] = X_train['CreditScore'].apply(credit_score_bucket)\n",
    "    X_test['CreditScore_Bucket'] = X_test['CreditScore'].apply(credit_score_bucket)\n",
    "    \n",
    "    X_train['BalanceGroup'] = pd.cut(X_train['Balance'], bins=[-1, 20000, 50000, 100000, 150000, 100000000], labels=[0, 1, 2, 3, 4])\n",
    "    X_test['BalanceGroup'] = pd.cut(X_test['Balance'], bins=[-1, 20000, 50000, 100000, 150000, 100000000], labels=[0, 1, 2, 3, 4])\n",
    "    \n",
    "    X_train = pd.get_dummies(X_train, columns=['BalanceGroup'], drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=['BalanceGroup'], drop_first=True)\n",
    "    \n",
    "    # One-hot encode the CreditScore_Bucket feature\n",
    "    X_train = pd.get_dummies(X_train, columns=['CreditScore_Bucket'], drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=['CreditScore_Bucket'], drop_first=True)\n",
    "\n",
    "    # Add new feature for the key finding: age group and number of products interaction\n",
    "    def age_group(age):\n",
    "        if age < 30:\n",
    "            return 'Under 30'\n",
    "        elif 30 <= age < 40:\n",
    "            return '30-40'\n",
    "        elif 40 <= age < 50:\n",
    "            return '40-50'\n",
    "        else:\n",
    "            return 'Over 50'\n",
    "\n",
    "    X_train['Age_Group'] = X_train['Age'].apply(age_group)\n",
    "    X_test['Age_Group'] = X_test['Age'].apply(age_group)\n",
    "    \n",
    "    X_train['AgeGroup_NumOfProducts_Interaction'] = X_train['Age_Group'] + '_' + X_train['NumOfProducts'].astype(str)\n",
    "    X_test['AgeGroup_NumOfProducts_Interaction'] = X_test['Age_Group'] + '_' + X_test['NumOfProducts'].astype(str)\n",
    "\n",
    "    # One-hot encode the AgeGroup_NumOfProducts_Interaction\n",
    "    X_train = pd.get_dummies(X_train, columns=['AgeGroup_NumOfProducts_Interaction'], drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=['AgeGroup_NumOfProducts_Interaction'], drop_first=True)\n",
    "\n",
    "    # Align the columns of X_test to match X_train (any missing columns will be filled with 0)\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    # Select the most important features, including the new interaction terms\n",
    "    feature_columns = [\n",
    "        'CreditScore',\n",
    "        'Gender',\n",
    "        'Age',\n",
    "        'Tenure',\n",
    "        'NumOfProducts',\n",
    "        'Age_Tenure_Ratio',\n",
    "        'Balance_Salary_Ratio',\n",
    "        'CreditScore_Tenure',\n",
    "        # One-hot encoded CreditScore_Bucket features (automatically handled),\n",
    "        # AgeGroup_NumOfProducts_Interaction one-hot encoded\n",
    "    ]\n",
    "\n",
    "    # Filter the training and testing data\n",
    "    X_train = X_train[feature_columns]\n",
    "    X_test = X_test[feature_columns]\n",
    "\n",
    "    # Apply Standard scaling to each column\n",
    "    X_train_scaled = (X_train - X_train.mean()) / X_train.std()\n",
    "    X_test_scaled = (X_test - X_train.mean()) / X_train.std()  # Use training mean/std for test data\n",
    "\n",
    "    return X_train_scaled.values, y_train.values, X_test_scaled.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    \"\"\" Perform k-fold cross-validation \"\"\"\n",
    "    # Convert X and y to NumPy arrays if they are not already\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Check if X and y have the same length\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(\"X and y must have the same length\")\n",
    "\n",
    "    fold_size = len(X) // n_splits\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)  # Shuffle the indices\n",
    "    scores = []\n",
    "\n",
    "    for fold in range(n_splits):\n",
    "        # Calculate the indices for validation set\n",
    "        val_indices = indices[fold * fold_size : (fold + 1) * fold_size] if fold < n_splits - 1 else indices[fold * fold_size :]\n",
    "\n",
    "        train_indices = np.concatenate([indices[:fold * fold_size], indices[(fold + 1) * fold_size:]])\n",
    "        \n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "        # Fit the model and predict\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_val_pred = knn.predictTrain(X_val)\n",
    "        \n",
    "        # Calculate accuracy or any other metric\n",
    "        score = np.mean(y_val_pred == y_val)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 10) (15000,) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "print(X.shape, y.shape, X_test.shape)\n",
    "\n",
    "# best_k = None\n",
    "# best_score = 0\n",
    "# for k in range(7, 12):  # Test k values from 1 to 20\n",
    "#     knn = KNN(k=k, distance_metric='euclidean')\n",
    "#     cv_scores = cross_validate(X, y, knn)\n",
    "#     mean_score = np.mean(cv_scores)\n",
    "#     print(k, mean_score)\n",
    "\n",
    "\n",
    "#     if mean_score > best_score:\n",
    "#         best_score = mean_score\n",
    "#         best_k = k\n",
    "\n",
    "# print(best_k, best_score)\n",
    "\n",
    "\n",
    "# knn = KNN(k=11, distance_metric='euclidean')\n",
    "# cv_scores = cross_validate(X, y, knn)\n",
    "\n",
    "# # Save test predictions\n",
    "# test_predictions = knn.predict(X_test)\n",
    "# pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs506",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
